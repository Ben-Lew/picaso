{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d54574d-fb93-4a0e-a6b8-9b7111c1d8e8",
   "metadata": {},
   "source": [
    "# Analyzing Models with Ultranest\n",
    "\n",
    "Now that we have climate models with grids, we need to take it to the next level of analysis with nested sampling utilizing [Ultranest](https://johannesbuchner.github.io/UltraNest/readme.html). This is important as to have a deeper and higher level of statistical support in your analysis of your data.\n",
    "\n",
    "\r\n",
    "In this tutorial you will learn how to create/read spectral, chemical, thermal plots and save your results to an [Xarray](https://docs.xarray.dev/en/stable/) for ease of accessibility of use in the future.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf790a22-1908-4d75-b43a-905f50412849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"ccfc9561-59e2-44e1-89e4-c42c96990a4c\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"ccfc9561-59e2-44e1-89e4-c42c96990a4c\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.4.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"ccfc9561-59e2-44e1-89e4-c42c96990a4c\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"ccfc9561-59e2-44e1-89e4-c42c96990a4c\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.4.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"ccfc9561-59e2-44e1-89e4-c42c96990a4c\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bokeh.plotting import figure, show\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#picaso\n",
    "import picaso.justplotit as jpi\n",
    "import picaso.analyze as lyz\n",
    "jpi.output_notebook()\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "#ULTRANEST\n",
    "import ultranest\n",
    "import ultranest.plot as uplt\n",
    "import ultranest.integrator as uint\n",
    "from ultranest.plot import PredictionBand\n",
    "\n",
    "import xarray as xr\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67481e1-4a14-42de-b1e7-1a66ef0843b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models in grid is 371\n",
      "For tint in planet_params grid is: ['200.0' '300.0']\n",
      "For heat_redis in planet_params grid is: ['0.5' '0.6' '0.7' '0.8']\n",
      "For mh in planet_params grid is: ['0.0' '0.3' '0.5' '0.7' '1.0' '1.3' '1.5' '1.7' '2.0']\n",
      "For cto in planet_params grid is: ['0.25' '0.5' '1.0' '1.5' '2.0' '2.5']\n"
     ]
    }
   ],
   "source": [
    "from model_setup import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581f6854-bd31-47be-aecb-33cf2c4134ea",
   "metadata": {},
   "source": [
    "# Reading the Results\n",
    "\n",
    "Now that we have run Ultranest, you should have an `emissions` folder with all of the Ultranest results.\r\n",
    "Let's read it and see what it gave us\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346d6d43-e0fc-4185-8f90-363d8179fb23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dirr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgridtrieval_files\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m uint\u001b[38;5;241m.\u001b[39mread_file(dirr, \u001b[38;5;28mlen\u001b[39m(params))\n\u001b[1;32m      3\u001b[0m res[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "dirr = 'gridtrieval_files'\n",
    "res = uint.read_file(dirr, len(params))\n",
    "res[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867f236c-8e5d-4be9-9d61-04474c65a6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['niter', 'logz', 'logzerr', 'logz_bs', 'logz_single', 'logzerr_tail', 'logzerr_bs', 'ess', 'H', 'Herr', 'posterior', 'weighted_samples', 'samples', 'maximum_likelihood', 'insertion_order_MWW_test'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458cc91-9b7a-44d6-ad1a-0f3b9b6aa2cf",
   "metadata": {},
   "source": [
    "We can see that it gave us a lot of statistical data which is what we want! There is a couple we really want to know:\r\n",
    "\r\n",
    "`logl`\r\n",
    "- Array of log likelihood at each point\r\n",
    "\r\n",
    "`paramnames`\r\n",
    "- Parameters we declared in run_ultranest.py\r\n",
    "\r\n",
    "`samples`\r\n",
    "- Sampled points from Ultranest\r\n",
    "\r\n",
    "Let's save our parameters/results and create our corner plot. This corner plot will show us the probability distributions of each parameter. In other words, it will show where the parameter has the highestmatching the datalclimate.\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8262681f-d9bb-4c11-aa30-178c9f7fde10",
   "metadata": {},
   "source": [
    "## Corner Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd6b7973-d6e3-42d5-b34f-f584ea7f214b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m samples \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m logl \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(res[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogl\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m uplt\u001b[38;5;241m.\u001b[39mcornerplot(results)\n",
      "File \u001b[0;32m~/anaconda3/envs/picaso311/lib/python3.11/site-packages/ultranest/plot.py:64\u001b[0m, in \u001b[0;36mcornerplot\u001b[0;34m(results, logger)\u001b[0m\n\u001b[1;32m     62\u001b[0m oldfunc \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mwarning\n\u001b[1;32m     63\u001b[0m logging\u001b[38;5;241m.\u001b[39mwarning \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m corner\u001b[38;5;241m.\u001b[39mcorner(data[mask,:], weights\u001b[38;5;241m=\u001b[39mweights[mask],\n\u001b[1;32m     65\u001b[0m               labels\u001b[38;5;241m=\u001b[39mparamnames, show_titles\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     66\u001b[0m logging\u001b[38;5;241m.\u001b[39mwarning \u001b[38;5;241m=\u001b[39m oldfunc\n",
      "File \u001b[0;32m~/anaconda3/envs/picaso311/lib/python3.11/site-packages/corner/corner.py:280\u001b[0m, in \u001b[0;36mcorner\u001b[0;34m(data, bins, range, axes_scale, weights, color, hist_bin_factor, smooth, smooth1d, labels, label_kwargs, titles, show_titles, title_quantiles, title_fmt, title_kwargs, truths, truth_color, scale_hist, quantiles, verbose, fig, max_n_ticks, top_ticks, use_math_text, reverse, labelpad, hist_kwargs, group, var_names, filter_vars, coords, divergences, divergences_kwargs, labeller, **hist2d_kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    245\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install arviz to use the advanced features of corner\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m         )\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m corner_impl(\n\u001b[1;32m    249\u001b[0m         data,\n\u001b[1;32m    250\u001b[0m         bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhist2d_kwargs,\n\u001b[1;32m    278\u001b[0m     )\n\u001b[0;32m--> 280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arviz_corner(\n\u001b[1;32m    281\u001b[0m     data,\n\u001b[1;32m    282\u001b[0m     bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m,\n\u001b[1;32m    284\u001b[0m     axes_scale\u001b[38;5;241m=\u001b[39maxes_scale,\n\u001b[1;32m    285\u001b[0m     weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[1;32m    286\u001b[0m     color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[1;32m    287\u001b[0m     hist_bin_factor\u001b[38;5;241m=\u001b[39mhist_bin_factor,\n\u001b[1;32m    288\u001b[0m     smooth\u001b[38;5;241m=\u001b[39msmooth,\n\u001b[1;32m    289\u001b[0m     smooth1d\u001b[38;5;241m=\u001b[39msmooth1d,\n\u001b[1;32m    290\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    291\u001b[0m     label_kwargs\u001b[38;5;241m=\u001b[39mlabel_kwargs,\n\u001b[1;32m    292\u001b[0m     titles\u001b[38;5;241m=\u001b[39mtitles,\n\u001b[1;32m    293\u001b[0m     show_titles\u001b[38;5;241m=\u001b[39mshow_titles,\n\u001b[1;32m    294\u001b[0m     title_quantiles\u001b[38;5;241m=\u001b[39mtitle_quantiles,\n\u001b[1;32m    295\u001b[0m     title_fmt\u001b[38;5;241m=\u001b[39mtitle_fmt,\n\u001b[1;32m    296\u001b[0m     title_kwargs\u001b[38;5;241m=\u001b[39mtitle_kwargs,\n\u001b[1;32m    297\u001b[0m     truths\u001b[38;5;241m=\u001b[39mtruths,\n\u001b[1;32m    298\u001b[0m     truth_color\u001b[38;5;241m=\u001b[39mtruth_color,\n\u001b[1;32m    299\u001b[0m     scale_hist\u001b[38;5;241m=\u001b[39mscale_hist,\n\u001b[1;32m    300\u001b[0m     quantiles\u001b[38;5;241m=\u001b[39mquantiles,\n\u001b[1;32m    301\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    302\u001b[0m     fig\u001b[38;5;241m=\u001b[39mfig,\n\u001b[1;32m    303\u001b[0m     max_n_ticks\u001b[38;5;241m=\u001b[39mmax_n_ticks,\n\u001b[1;32m    304\u001b[0m     top_ticks\u001b[38;5;241m=\u001b[39mtop_ticks,\n\u001b[1;32m    305\u001b[0m     use_math_text\u001b[38;5;241m=\u001b[39muse_math_text,\n\u001b[1;32m    306\u001b[0m     reverse\u001b[38;5;241m=\u001b[39mreverse,\n\u001b[1;32m    307\u001b[0m     labelpad\u001b[38;5;241m=\u001b[39mlabelpad,\n\u001b[1;32m    308\u001b[0m     hist_kwargs\u001b[38;5;241m=\u001b[39mhist_kwargs,\n\u001b[1;32m    309\u001b[0m     group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[1;32m    310\u001b[0m     var_names\u001b[38;5;241m=\u001b[39mvar_names,\n\u001b[1;32m    311\u001b[0m     filter_vars\u001b[38;5;241m=\u001b[39mfilter_vars,\n\u001b[1;32m    312\u001b[0m     coords\u001b[38;5;241m=\u001b[39mcoords,\n\u001b[1;32m    313\u001b[0m     divergences\u001b[38;5;241m=\u001b[39mdivergences,\n\u001b[1;32m    314\u001b[0m     divergences_kwargs\u001b[38;5;241m=\u001b[39mdivergences_kwargs,\n\u001b[1;32m    315\u001b[0m     labeller\u001b[38;5;241m=\u001b[39mlabeller,\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhist2d_kwargs,\n\u001b[1;32m    317\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/picaso311/lib/python3.11/site-packages/corner/arviz_corner.py:135\u001b[0m, in \u001b[0;36marviz_corner\u001b[0;34m(data, bins, range, axes_scale, weights, color, hist_bin_factor, smooth, smooth1d, labels, label_kwargs, titles, show_titles, title_fmt, title_kwargs, truths, truth_color, scale_hist, quantiles, verbose, fig, max_n_ticks, top_ticks, use_math_text, reverse, labelpad, hist_kwargs, group, var_names, filter_vars, coords, divergences, divergences_kwargs, labeller, **hist2d_kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     titles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m    131\u001b[0m         [np\u001b[38;5;241m.\u001b[39masarray(titles[k])\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m var_names]\n\u001b[1;32m    132\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Coerce the samples into the expected format\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m plotters], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    136\u001b[0m fig \u001b[38;5;241m=\u001b[39m corner_impl(\n\u001b[1;32m    137\u001b[0m     samples,\n\u001b[1;32m    138\u001b[0m     bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhist2d_kwargs,\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Get diverging draws and combine chains\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/picaso311/lib/python3.11/site-packages/numpy/core/shape_base.py:445\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    443\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [asanyarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    447\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "res[1]['paramnames'] =  params\n",
    "results = res[1]\n",
    "paramnames = results['paramnames']\n",
    "samples = results['samples']\n",
    "logl = np.array(res[0]['logl'])\n",
    "\n",
    "uplt.cornerplot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a73ac95-6db0-4e30-af96-21e3c06c4911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tint_mean</th>\n",
       "      <th>tint_stdev</th>\n",
       "      <th>tint_median</th>\n",
       "      <th>tint_errlo</th>\n",
       "      <th>tint_errup</th>\n",
       "      <th>heat_redis_mean</th>\n",
       "      <th>heat_redis_stdev</th>\n",
       "      <th>heat_redis_median</th>\n",
       "      <th>heat_redis_errlo</th>\n",
       "      <th>heat_redis_errup</th>\n",
       "      <th>mh_mean</th>\n",
       "      <th>mh_stdev</th>\n",
       "      <th>mh_median</th>\n",
       "      <th>mh_errlo</th>\n",
       "      <th>mh_errup</th>\n",
       "      <th>cto_mean</th>\n",
       "      <th>cto_stdev</th>\n",
       "      <th>cto_median</th>\n",
       "      <th>cto_errlo</th>\n",
       "      <th>cto_errup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.997811</td>\n",
       "      <td>0.00171</td>\n",
       "      <td>299.998213</td>\n",
       "      <td>299.996093</td>\n",
       "      <td>299.99946</td>\n",
       "      <td>0.502143</td>\n",
       "      <td>0.00159</td>\n",
       "      <td>0.501832</td>\n",
       "      <td>0.500562</td>\n",
       "      <td>0.503811</td>\n",
       "      <td>1.997757</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>1.998114</td>\n",
       "      <td>1.995981</td>\n",
       "      <td>1.999404</td>\n",
       "      <td>2.497811</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>2.498122</td>\n",
       "      <td>2.496127</td>\n",
       "      <td>2.499456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tint_mean  tint_stdev  tint_median  tint_errlo  tint_errup  \\\n",
       "0  299.997811     0.00171   299.998213  299.996093   299.99946   \n",
       "\n",
       "   heat_redis_mean  heat_redis_stdev  heat_redis_median  heat_redis_errlo  \\\n",
       "0         0.502143           0.00159           0.501832          0.500562   \n",
       "\n",
       "   heat_redis_errup   mh_mean  mh_stdev  mh_median  mh_errlo  mh_errup  \\\n",
       "0          0.503811  1.997757  0.001689   1.998114  1.995981  1.999404   \n",
       "\n",
       "   cto_mean  cto_stdev  cto_median  cto_errlo  cto_errup  \n",
       "0  2.497811   0.001678    2.498122   2.496127   2.499456  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = jdi.pd.read_csv(os.path.join(dirr, 'info','post_summary.csv'))\n",
    "median_val = [summary[i+'_'+'median'].values[0] for i in params]\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4621d836-9d68-4325-9d04-c64ce124950a",
   "metadata": {},
   "source": [
    "# Deciding the best fit physical parameters\r\n",
    "\r\n",
    "There are two paths we can take. \r\n",
    "1) Find the parameter values where the max log likelihood lie.\r\n",
    "2) Find the parameter values where the median values lie.\r\n",
    "\r\n",
    "It is really important to take the right path and report what you use. We already have the median values from the corner plot above. In this specific case, let's begin by printing the max log likelfirstod ves.\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8492b075-a2fb-4071-88e1-bfd1e9d1ae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tint 299.99756358470484\n",
      "heat_redis 0.5038607196993385\n",
      "mh 1.9955581068046737\n",
      "cto 2.499288249359772\n"
     ]
    }
   ],
   "source": [
    "#Print max log likelihood parameters\n",
    "for i ,ip in enumerate(paramnames): \n",
    "    print(ip,samples[np.argmax(logl),i])\n",
    "maxlog_val = samples[np.argmax(logl),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf653b01-f193-4303-ad4d-a01d3f1a0e8c",
   "metadata": {},
   "source": [
    "Uh oh! Running this twice produces different results. Here are two runs:\n",
    "> tint 242.90576849771628\n",
    ">\n",
    "> heat_redis 0.614576599525345\n",
    "> \n",
    "> mh 1.0190034348328623\n",
    ">\n",
    "> cto 0.6516417142035135\n",
    "\n",
    "vs\n",
    "\n",
    "> tint 345.25805285732406\n",
    ">\n",
    "> heat_redis 0.5943213159419377\n",
    ">\n",
    "> mh 1.162968230864151\n",
    ">\n",
    "> cto 0.4563875323149711\n",
    "> \n",
    "\n",
    "This means it is much more reliable to use and report the median value parameters, rather than the changing log likelihood values. Let's use the median values for the climate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2cd69-4bc0-4e98-9f3d-2fb7e46f4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_xarr_dir = \"xarrays/climate/hat-p-26_tint300_rfacv0.5_mh+130_cto100.nc\" #note we use tint: 300, r_facv/heat_redis: 0.5, mh:1.30, CtoO: 1.0\n",
    "MODEL = getattr(model_set,model_type)\n",
    "resultx, resulty = MODEL(median_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8999690e-d649-4571-a230-ef79702fc1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab the climate\n",
    "xr_usr=jdi.xr.load_dataset(climate_xarr_dir)\n",
    "opa = jdi.opannection(filename_db=opa_dir)\n",
    "case = jdi.input_xarray(xr_usr, opa)\n",
    "\n",
    "#copy over the climate\n",
    "og_atmo = jdi.copy.deepcopy(case.inputs['atmosphere']['profile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed66ff-0647-420d-a50e-74a0c37d5d65",
   "metadata": {},
   "source": [
    "Let's check the chi-square fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc9cad-426a-423a-b113-88908ca53374",
   "metadata": {},
   "source": [
    "## Chi-Square Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadae7b4-5b6c-41a8-b600-762dcfd25728",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd=[]\n",
    "yd=[]\n",
    "datay=[]\n",
    "datae=[]\n",
    "for i in data_dict.keys(): \n",
    "    datay+=list(data_dict[i][1])\n",
    "    datae+=list(data_dict[i][2])\n",
    "    xd1, yd1=jdi.mean_regrid(resultx, resulty, newx=data_dict[i][0])\n",
    "    xd+=list(xd1)\n",
    "    yd+=list(yd1)\n",
    "\n",
    "chisq_best_fit_perdata = lyz.chi_squared(np.array(datay),np.array(datae),\n",
    "                np.array(yd),0)\n",
    "\n",
    "print(chisq_best_fit_perdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc2ac1-d474-484b-8f9d-f77243b866b2",
   "metadata": {},
   "source": [
    "# Spectral Anaylsis\n",
    "\n",
    "It is important to check if the spectral data points from Ultranest align with our actual data.\n",
    "\n",
    "To begin, let's plot the spectrum data with our sampled results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c4363-651b-493d-bca9-e09596dbdee3",
   "metadata": {},
   "source": [
    "## Spectrum Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bfaeb2-f685-4491-8f4d-4da043b205d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_200, y_200=jdi.mean_regrid(resultx, resulty, R=200)\n",
    "fig = figure(x_axis_type='log', width=700, height=300)\n",
    "for i in data_dict.keys():\n",
    "  \n",
    "    jpi.plot_errorbar(1e4/data_dict[i][0], \n",
    "                  data_dict[i][1], \n",
    "                  data_dict[i][2], fig, \n",
    "                point_kwargs={'color':'black','size':10, 'legend_label':\"Observational Data\"},\n",
    "                      error_kwargs={'color':'black','line_width':4})\n",
    "\n",
    "fig.line(1e4/x_200, y_200,line_width=4,legend_label=\"Sampled Points\")\n",
    "fig.legend.location = \"top_left\"\n",
    "\n",
    "jpi.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed45de-bad6-48cd-a408-440b9c9f1944",
   "metadata": {},
   "source": [
    "Now, let's see the eclipse depth. We are first going to create a band from our observation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a268be63-64b4-41f6-85e6-e10518472f4a",
   "metadata": {},
   "source": [
    "## Eclipse Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d7372-cf9a-41f5-916c-cfc06e9e48d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the band and the error region\n",
    "MODEL = getattr(model_set,model_type)\n",
    "\n",
    "def model_w_regrid(eval_at):\n",
    "    resultx, resulty = MODEL(eval_at)\n",
    "    x, y=jdi.mean_regrid(resultx, resulty, newx=x_200)\n",
    "    return y\n",
    "    \n",
    "\n",
    "\n",
    "n_draws = 200\n",
    "samples = results['samples']\n",
    "draws=np.random.randint(0, samples.shape[0], n_draws)\n",
    "\n",
    "band = PredictionBand(1e4/x_200)\n",
    "for idraw in draws:\n",
    "    band.add(model_w_regrid(samples[idraw,:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f8f625-1c40-4e93-9dae-2c86339418b4",
   "metadata": {},
   "source": [
    "Next, let's overplot our observation data band with the Ultranest sampled points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a8494-1ff4-4a57-887e-f4de0bafc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PuBuGn = jpi.pals.PuBuGn3\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    " \n",
    "for i in data_dict.keys():\n",
    "    ax.errorbar(x=1e4/data_dict[i][0], y=data_dict[i][1], \n",
    "             yerr=data_dict[i][2], \n",
    "             marker='x', ls=' ')\n",
    "    \n",
    "band.line(color='k')\n",
    "spec_sigmas_hi = {}\n",
    "spec_sigmas_lo = {}\n",
    "\n",
    "for q ,c,key in zip([k/100/2 for k in [68.27, 95.45, 99.73]], PuBuGn, ['1sig','2sig','3sig']): \n",
    "    band.shade(q=q, color=c, alpha=0.5)\n",
    "    spec_sigmas_lo[key] = band.get_line(0.5 - q)\n",
    "    spec_sigmas_hi[key] = band.get_line(0.5 + q)\n",
    "\n",
    "spec_median_best_fit = band.get_line(0.5)\n",
    "\n",
    "ax.set_ylabel('Eclipse Depth', fontsize=16)\n",
    "ax.set_xlabel('Wavelength [$\\mu$m]', fontsize=16)\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=13)\n",
    "ax.tick_params(axis='y', labelsize=13)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(3,12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5e0e4-280b-4f78-a1d7-f554e8a21012",
   "metadata": {},
   "source": [
    "Great! It seems like our sampled points align well with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5fbe3-abd8-43e2-9ec5-c28a92015801",
   "metadata": {},
   "source": [
    "# Pressure-Temperature Analysis\r\n",
    "\r\n",
    "With our spectral data checked out, we need to next check if our P-T profile is aligned well with what our climate that we have run before says its i\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef1d26-ac54-4c9b-8ac8-2ad0a22fa6fa",
   "metadata": {},
   "source": [
    "First, we need to create our median band for our P-T profile alongside the 1-σ, 2-σ, 3-σ error from our Ultranest sampled points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109aa9cd-860d-4de7-9f5b-333d0ace54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create band for p-t profile\n",
    "def pt_band(params):\n",
    "    final_goal = params[0:len(grid_parameters_unique.keys())]\n",
    "    temp = lyz.custom_interp(final_goal, fitter, grid_name, to_interp='custom',\n",
    "                                 array_to_interp=np.reshape(fitter.temperature['cldfree'],(3,6,8,4,91)))\n",
    "    return temp\n",
    "    \n",
    "\n",
    "\n",
    "n_draws = 600\n",
    "samples = results['samples']\n",
    "draws=np.random.randint(0, samples.shape[0], n_draws)\n",
    "\n",
    "pressure = np.reshape(fitter.pressure['cldfree'],(3,6,8,4,91))[0,0,0,0,:]\n",
    "band = PredictionBand(pressure)#[6,4,1,1,1,:])\n",
    "for idraw in draws:\n",
    "    band.add(pt_band(samples[idraw,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af49dc2-2c8e-4724-a9b9-740f3bc7c257",
   "metadata": {},
   "source": [
    "Next, we need to plot this band and overplot our climate model data to see if they are within some σ of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f420e0-552c-431f-b72c-8ba406297fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot it!\n",
    "pressure = np.reshape(fitter.pressure['cldfree'],(3,6,8,4,91))[0,0,0,0,:]\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "band.line(color='k')\n",
    "sigmas_hi = {}\n",
    "sigmas_lo = {}\n",
    "all_median={}\n",
    "\n",
    "for q ,c,key in zip([k/100/2 for k in [68.27, 95.45, 99.73]], PuBuGn, ['1sig','2sig','3sig']): \n",
    "    #band.shade(q=q, color=c, alpha=0.5)\n",
    "    sigmas_lo[key] = band.get_line(q=0.5 - q)\n",
    "    all_median[key+'_lo_temperature'] = sigmas_lo[key]\n",
    "    sigmas_hi[key] = band.get_line(q=0.5 + q)\n",
    "    ax.fill_betweenx(pressure,sigmas_lo[key] ,sigmas_hi[key], color=c, alpha=0.5)\n",
    "    all_median[key+'_hi_temperature'] = sigmas_hi[key]\n",
    "median_best_fit = band.get_line(0.5)\n",
    "all_median['temperature'] = median_best_fit\n",
    "ax.plot(median_best_fit,pressure, color='black',alpha=1, label='median')\n",
    "ax.plot(og_atmo['temperature'], og_atmo['pressure'], label='xarray', ls='--')\n",
    "\n",
    "ax.set_ylabel('Pressure [bar]', fontsize=16)\n",
    "ax.set_xlabel('Temperature [K]', fontsize=16)\n",
    "# Set the font size of major tick labels on the x-axis and y-axis\n",
    "ax.tick_params(axis='x', labelsize=13)\n",
    "ax.tick_params(axis='y', labelsize=13)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim([1e2,1e-6])\n",
    "ax.set_xlim([800,3000])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27cd4a0-f67d-4ba4-8eca-7514510725d7",
   "metadata": {},
   "source": [
    "Looks dead on! This is great, our climate code is fully agreeing with the Ultranest sampled points. Just like the eclipse depth, the different shading represents 1-σ, 2-σ, 3-σ error. This is right down the middle which is fantastic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c88a812-ae35-49d8-8af6-b9b832d25662",
   "metadata": {},
   "source": [
    "# Chemical Analysis\n",
    "\n",
    "This portion may be a bit more difficult considering we are not using transmission data, however we still can withdraw and dissect some really useful scientific data about the chemical state of the atmosphere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da189e-8dc0-41f0-bd4e-231792db73d9",
   "metadata": {},
   "source": [
    "Let's decide which molecules to analyze for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192bea76-b83a-44bb-a25d-a243f3dfa3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mols=['CO2','CH4','CO','H2O']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914edc6f-c832-40c6-ba2a-c19716b505c5",
   "metadata": {},
   "source": [
    "This is a very similar process as before. Create the chemical band, overplot with our climate data, and see the σ tolerance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f66a0d-5307-4a39-94f6-0ffdd3879d5e",
   "metadata": {},
   "source": [
    "## Mixing Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7ce63-1a5e-45f2-a73b-3ef64ba55dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chem = fitter.chemistry['cldfree']\n",
    "#create our chemistry band for each chemical\n",
    "def chem_band(params,mol):\n",
    "    to_interp = np.reshape(chem[mol],(3,6,8,4,91))\n",
    "    final_goal = params[0:len(grid_parameters_unique.keys())]\n",
    "    temp = lyz.custom_interp(final_goal, fitter, grid_name, to_interp='custom',\n",
    "                                       array_to_interp=to_interp )\n",
    "    return temp\n",
    "    \n",
    "\n",
    "for imol in mols:\n",
    "    n_draws = 200\n",
    "    samples = results['samples']\n",
    "    draws=np.random.randint(0, samples.shape[0], n_draws)\n",
    "\n",
    "    band = PredictionBand(pressure)\n",
    "    for idraw in draws:\n",
    "        band.add(chem_band(samples[idraw,:], imol))\n",
    "        \n",
    "    median_best_fit = band.get_line(0.5)\n",
    "    all_median[imol] = median_best_fit\n",
    "    \n",
    "    for q ,c,key in zip([k/100/2 for k in [68.27, 95.45, 99.73]], PuBuGn, ['1sig','2sig','3sig']): \n",
    "        sigmas_lo[key] = band.get_line(q=0.5 - q)\n",
    "        all_median[key+'_lo_'+imol] = sigmas_lo[key]\n",
    "        sigmas_hi[key] = band.get_line(q=0.5 + q)\n",
    "        ax.fill_betweenx(pressure,sigmas_lo[key] ,sigmas_hi[key], color=c, alpha=0.5)\n",
    "        all_median[key+'_hi_'+imol] = sigmas_hi[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86aa37-3e5a-4f06-b5c5-f96375bf066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot it!\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "for imol in mols:\n",
    "    ax.plot(all_median[imol],pressure,label=imol)\n",
    "    ax.fill_betweenx(pressure,all_median['3sig'+'_lo_'+imol] ,\n",
    "                     all_median['3sig'+'_hi_'+imol], alpha=0.5)\n",
    "\n",
    "ax.plot(og_atmo['CO2'], og_atmo['pressure'], label='xarr CO2', ls=\"--\")\n",
    "ax.plot(og_atmo['CH4'], og_atmo['pressure'], label='xarr CH4', ls=\"--\")\n",
    "ax.plot(og_atmo['CO'], og_atmo['pressure'], label='xarr CO', ls=\"--\")\n",
    "ax.plot(og_atmo['H2O'], og_atmo['pressure'], label='xarr H2O', ls=\"--\")\n",
    "ax.set_ylabel('Pressure [bar]', fontsize=16)\n",
    "ax.set_xlabel('(v/v)', fontsize=16)\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=13)\n",
    "ax.tick_params(axis='y', labelsize=13)\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim([1e2,1e-6])\n",
    "ax.set_xlim([1e-7,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c54f96-e751-4aff-a9f4-a75668d56a58",
   "metadata": {},
   "source": [
    "Since we don't have transmission data, our errors are much larger thus we only plot 3-σ shaded regions. But, it seems like our climate code and Ultranest sampled points are still in tandem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4ecf1-a628-4d89-b3a7-00aa8c9013f0",
   "metadata": {},
   "source": [
    "Next, let's analyze which molecule is causing the biggest impact to our data by using the \"leave-one-out\" method. This can tell us which molecules are more than likely present than others. This may take a while as it effectively has to recreate the spectrum as many times as the molecules desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962e4ff-019e-4f7e-97b4-3609c7d10007",
   "metadata": {},
   "source": [
    "## \"Leave One Out\" Method (Molecular Contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873fa21-1c72-49b0-9708-e03115763bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "\n",
    "w,f,l =[],[],[]\n",
    "for iex in mols + [None]:\n",
    "    case.atmosphere(df = og_atmo, exclude_mol=iex, delim_whitespace=True)\n",
    "    df= case.spectrum(opa, full_output=True,calculation='thermal')\n",
    "    #print(df.keys())\n",
    "    wno, rprs2  = df['wavenumber'] , df['fpfs_thermal']\n",
    "    wno, rprs2 = jdi.mean_regrid(wno, rprs2, R=150)\n",
    "    w +=[wno]\n",
    "    f+=[rprs2]\n",
    "    if iex==None:\n",
    "        leg='all'\n",
    "    else:\n",
    "        leg = f'No {iex}'\n",
    "    l+=[leg]\n",
    "jpi.show(jpi.spectrum(w,f,legend=l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6847d10-f739-4f12-9dad-468dfac32607",
   "metadata": {},
   "source": [
    "This is awesome! We can clearly see and have a strong reasoning that H2O and CO2 are in the atmosphere. If they weren't present, the spectrum would completely veer off course of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a40be-d71c-4822-8c48-d64456e5ada0",
   "metadata": {},
   "source": [
    "# Thermal Contribution\n",
    "\n",
    "Let's also look at the thermal contribution. This can give us the understanding of what fluxes are emitted at which pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafacfc1-7672-4dd6-a2c6-dfd251bfd23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=case.spectrum(opa, full_output=True, calculation='emissions')\n",
    "fig, ax, CF = jpi.thermal_contribution(df['full_output'],\n",
    "                                       norm=jpi.colors.LogNorm(vmin=1e9, vmax=1e12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846a4ceb-1dbe-463d-99e8-ec1163282d15",
   "metadata": {},
   "source": [
    "# Building and Exporting Xarray\r\n",
    "\r\n",
    "Now that our analysis of the sampled points is completed to our satisfaction, let's build and export an xarray of all the data used so anyone can make these plots and do any other analysis they desire. This is very important as you can effectively throw the whole model to someone and they can do whatever they want without having to rerun any modeling/sampling method\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ac201-2771-4118-b611-50c399201a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from astropy.utils.misc import JsonCustomEncoder\n",
    "import numpy.ma as ma\n",
    "\n",
    "data_vars=dict(\n",
    "        temperature_1sig_lo= ([\"pressure\"], ma.getdata(all_median['1sig_lo_temperature']), {'units': 'Kelvin'}),\n",
    "        temperature_1sig_hi= ([\"pressure\"], ma.getdata(all_median['1sig_hi_temperature']), {'units': 'Kelvin'}),\n",
    "        temperature_median= ([\"pressure\"], ma.getdata(all_median['temperature']),{'units': 'Kelvin'}),\n",
    "        eclipse_depth_median=(['wavelength'], spec_median_best_fit,{'units': 'Fp/F*'}),\n",
    "        eclipse_depth_1sig_lo=(['wavelength'], ma.getdata(spec_sigmas_lo['1sig']),{'units': 'Fp/F*'}),\n",
    "        eclipse_depth_1sig_hi=(['wavelength'], ma.getdata(spec_sigmas_hi['1sig']),{'units': 'Fp/F*'}),\n",
    "\n",
    "    )\n",
    "\n",
    "for i in mols:\n",
    "    data_vars[i+\"_median\"] = ([\"pressure\"], all_median[i])\n",
    "    data_vars[i+\"_1sig_lo\"] = ([\"pressure\"], all_median[\"1sig_lo_\"+i])\n",
    "    data_vars[i+\"_1sig_hi\"] = ([\"pressure\"], all_median[\"1sig_hi_\"+i])\n",
    "build_xarray = xr.Dataset(\n",
    "    data_vars=data_vars,\n",
    "    coords=dict(\n",
    "        pressure=([\"pressure\"], pressure, {'units': 'bar'}),\n",
    "        wavelength=(['wavelength'], x_200, {'units': '1/cm'}),\n",
    "    ),\n",
    "    #change this with your information!\n",
    "    attrs=dict(author=\"Dominic Doud\",\n",
    "               contact=\"dominic.doud@nasa.gov\",\n",
    "               model=\"PICASO Chemeq Grid + Virga fit with Ultranest\",\n",
    "               chisq_best_fit_perdata = chisq_best_fit_perdata,\n",
    "               code=\"PICASO,Ultranest,Virga\", #required, in this case I used numpy to make my fake model.\n",
    "               median_params=json.dumps({ip:median_val[i] for i,ip in enumerate(paramnames)},cls=JsonCustomEncoder),\n",
    "               summary=summary.to_json()\n",
    "              ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3284cf4-8f31-4250-bb85-6bc4c4cf9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f70c0ae-69b5-4b7b-a3c4-c18e9d74229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_xarray.to_netcdf('final_picaso_cld_free_w_virga_medianfit.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
